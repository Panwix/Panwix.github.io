---
layout: post
title: hadoop
categories:  大数据平台
tags: hadoop
fullview: true
---

# Hadoop学习
## 大数据技术的相关概念
1. Hadoop是开源的分布式存储＋分布式计算平台
2. Hadoop两个核心组成
	1. HDFS:分布式文件系统，存储海量的数据
	2. MapReduce:并行处理框架，实现任务分解和调度
3. Hadoop可以用来搭建大型数据仓库，PB级数据的存储，处理，分析，统计等业务
4. Hadoop的优势：
	1.高扩展
	2.低成本
	3.成熟的生态圈
5. Hadoop的生态系统及版本
	1. HIVE：将sql语句转换成hadoop任务
	2. HBASE：存储结构化数据的分布式数据库（放弃了事务特性）	3. zookeeper: 管理工具		

## Hadoop的架构和运行机制
### HDFS
1. 基本概念：块（Block） NameNode DataNode:
	1. HDFS文件被分成块进行存储，每块的默认大小为64MB，块是文件存储处理的逻辑单元
	2. NameNode是管理节点，存放文件元数据
		1. 文件与数据块的映射表
		2. 数据块与数据节点的映射表
	3. DataNode是HDFS的工作节点，存放数据块
2. HDFS中数据管理与容错
	1. 每个数据块3个副本，分布在两个机架内的三个节点
	2. DataNode定期向NameNode发送心跳消息
	3. 二级NameNode定期同步元数据映像文件和修改日志，当NameNode发生故障时，备胎转正
3. HDFS中文件读写的流程
	1. 读 客户端发送文件读取请求到NameNode,NameNode返回元数据到客户端，客户端从DataNode中读取Blocks
	2. 写 客户端先将文件拆分成块然后请求NameNode，NameNode返回DataNodes信息给客户端，客户端根据返回的信息在DataNode中写入Block（一个一个来），写完后Block流水线复制另外两份，完成后更新元数据给NameNode
4. HDFS特点
	1. 数据冗余，硬件容错
	2. 流式的数据访问（写一次读多次）
	3. 存储大文件
5. 适用性和局限性：适合数据批量读写，吞吐量高；不适合交互式应用，低延迟很难满足；适合一次写入多次读写，顺序读写；不支持多用户并发写相同文件
6. HDFS使用
	1. 写 hadoop fs -put hadoop-env.sh input/
	2. 读 hadoop fs -cat input/hadoop-env.sh
	3. 下载 hadoop fs -get input/hadoop-env.sh hadoop-env2.sh
	4. 查看文件系统中的所有信息 hadoop dfsadmin -report

### MapReduce
1. 原理：分而治之，一个大任务分成多个小的子任务（map），并行执行后，合并结果（reduce）
2. 概念
	1. job & Task：job是一次任务，会被拆分成多个task，task分为MapTask和ReduceTask
	2. jobTracker：分发map任务和reduce任务给Map TaskTracker和reduce TaskTracker。
		1.角色：作业调度；分配任务，监控任务的执行进度；监控tasktracker的状态
	3.TaskTracker：执行任务；回报任务状态
3. 流程
	1. 输入数据分片放到TaskTracker里面（分配map任务）之后产生中间结果（key－value对）根据映射规则进行交换到reduce任务也是tasktracker（由jobTracker分配）输出结果到HDFS
	2. 容错机制：重复执行 4次后放弃执行；推测执行 某个tasktracker执行慢再找一个tasktracker执行相同的任务


## Hadoop的安装配置
1. Linux环境：租用云主机，阿里云，UnitedStack等
2. 配置Hadoop
	1. 下载 wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-1.2.1/hadoop-1.2.1.tar.gz
	2. 解压缩
	3. conf文件夹下配置mapred-site.xml, core-site.xml, hdfs-site.xml, hadoop-env.sh
		1. hadoop-env.sh配置jdk路径 /etc/profile
		2. core－site.xml
			1. hadoop.tmp.dir /hadoop hadoop的工作目录
			2. dfs.name.dir /hadoop/name 所有源数据的目录
			3. fs.default.name hdfs://localhost:9000 文件系统的nameload如何访问
		3. hdfs-site.xml 数据的存放目录 dfs.data.dir /hadoop/data
		4. mapred-site.xml 任务调度器如何访问 mapred.job.tracker localhost:9001
	4. 在系统中配置hadoop路径	/etc/profile
	5. hadoop namenode -format
	6. start-all.sh
	7. jps 使用jps查看hadoop是否正常运行
	8. hadoop fs -ls / 查看文件系统
