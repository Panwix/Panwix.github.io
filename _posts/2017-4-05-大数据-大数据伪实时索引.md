---
layout: post
title: 大数据伪实时索引
categories:  大数据
tags: 索引
fullview: true
---

# 大数据伪实时索引

### Flume NG
Flume NG是一个分布式，高可用，可靠的系统，它能将不同的海量数据收集，移动并存储到一个数据存储系统中。轻量，配置简单，适用于各种日志收集，并支持Failover和负载均衡。并且它拥有非常丰富的组件。Flume NG采用的是三层架构：Agent层，Collector层和Store层，每一层均可水平拓展。其中Agent包含Source，Channel和Sink，三者组建了一个Agent。
三者的职责：

* Source：用来消费（收集）数据源到Channel组件中
* Channel：中转临时存储，保存所有Source组件信息
* Sink：从Channel中读取，读取成功后会删除Channel中的信息

从外部系统（Web Server）中收集产生的日志，然后通过Flume的Agent的Source组件将数据发送到临时存储Channel组件，最后传递给Sink组件，Sink组件直接把数据存储到HDFS文件系统中。

### morphline
morphline是一个开源的ETL框架。它用于构建、改变基于Hadoop进行ETL（extract、transfer、load）的流式处理程序。morphline是一个富配置文件可以很简单得定义一个转化链，用于从任何数据源消费任何类型的数据，处理数据然后加载结果到Hadoop组件中。它用简单的配置步骤代替了Java编程。

### RNT(伪实时数据索引)
要实现近实时搜索，就必须有一种机制来实时的处理数据然后生成到solr的索引中去，flume-ng刚好提供了这样一种机制，它可以实时收集数据,然后通过MorphlineSolrSink对数据进行ETL，最后写入到solr的索引中，这样就能在solr搜索引擎中近实时的查询到新进来的数据了。

1. 在cm中flume的配置中配置Flume-NG Solr接收器，morphlines配置文件，首先执行了一个readJson命令，将读入的event的内容转换成了一个json对象，然后使用extractJsonPaths命令抽取json对象的具体字段值并重新赋值给另一个字段，最后执行sanitizeUnknownSolrFields命令舍弃solr的schema中没有配置的field字段，即通过ETL之后record最终只保留solr中已配置的字段。然后通过loadSolr指令将最终的record提交到solr。
2. flume agent的配置，注意点就是我们在CM中配置的Flume-NG Solr 接收器，所以morphlineFile直接写morphlines.conf就行了，否则需要写绝对路径,不然没法找到morphlines的配置文件。
3. 面三部准备好之后，启动agent,然后在shell控制台执行 flume-ng avro-client -H localhost -p 44444 -F file01命令，将我们第一步创建的数据文件提交给agent。
4. 执行完后，如果没报错的话，可以去solr中通过http://xxxxx:xxxx/solr/collection1/select?q=*:*查询一下这两条数据是不是已经创建到搜索引擎的索引库中
